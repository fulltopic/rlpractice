# PPO Resources

## Reference

* [PPO Interpretation](https://stackoverflow.com/questions/46422845/what-is-the-way-to-understand-proximal-policy-optimization-algorithm-in-rl)

* [CartPole PPO](https://github.com/4kasha/CartPole_PPO)

* [A pong params ref](https://github.com/ray-project/ray/blob/master/rllib/tuned_examples/ppo/pong-ppo.yaml)

* [GAE](https://towardsdatascience.com/generalized-advantage-estimate-maths-and-code-b5d5bd3ce737)

* [A Continuous Pytorch PPO](https://github.com/nikhilbarhate99/PPO-PyTorch/blob/master/PPO.py)

* [RLlib ppo](https://docs.ray.io/en/master/rllib-algorithms.html#proximal-policy-optimization-ppo)

* [Ray Project](https://github.com/ray-project/rl-experiments)

* [Spinup](https://spinningup.openai.com/en/latest/algorithms/ppo.html)

* [Hyperparameters range](https://medium.com/aureliantactics/ppo-hyperparameters-and-ranges-6fc2d29bccbe)

* [KL](http://joschu.net/blog/kl-approx.html)

* [Value clip](https://github.com/openai/baselines/issues/91)

* [PPO some feedback](https://github.com/openai/baselines/issues/445)

* [PPO value loss](https://github.com/openai/baselines/issues/91)

* [PPO pong 1](http://www.sagargv.com/blog/pong-ppo/)

* [PPO stackoverflow](https://stackexchange.com/search?q=ppo)

* [A Zhihu reproduce](https://zhuanlan.zhihu.com/p/50322028)

* [hints from stable-baselines3 ppo code reading](https://blog.csdn.net/jinzhuojun/article/details/80417179)

* [About lambda](https://slm-lab.gitbook.io/slm-lab/using-slm-lab/search-spec-ppo-on-breakout)

* [Clip objective function](https://drive.google.com/file/d/1PDzn9RPvaXjJFZkGeapMHbHGiWWW20Ey/view)

* [A simple implementation codes reading](https://towardsdatascience.com/a-graphic-guide-to-implementing-ppo-for-atari-games-5740ccbe3fbc)

## TODO

* Distributed PPO

* Difference betweeen initializer: orthogonal, xavier, kaiming are all suggested

* How clip works in backward?

* Review GAE: how it balanced bias and variance?

* Retrace

## Advanced (Not to read yet)

* [Deceptive Gradient](https://arxiv.org/pdf/2006.08505.pdf)

* Quality Deversity

* [Exploration Topic](https://stackoverflow.com/questions/63047930/reinforcement-learning-driving-around-objects-with-ppo)

* ACKTR

